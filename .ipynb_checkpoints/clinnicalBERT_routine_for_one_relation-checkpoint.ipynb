{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate negative pairs by finding similar concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[                                                                        ]   0%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RELA_count=  35226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import progressbar\n",
    "import os\n",
    "\n",
    "RELA = 'disease_has_finding'\n",
    "RELA_count = 0\n",
    "\n",
    "CUI1_set = set()\n",
    "CUI2_set = set()\n",
    "rela_dict = dict()\n",
    "\n",
    "with open('./relas/'+RELA+'.csv') as f:\n",
    "    reader = csv.reader(f, delimiter=',')\n",
    "    row1 = next(reader)\n",
    "    for row in reader:\n",
    "        RELA_count += 1\n",
    "        if row[1] not in CUI1_set:\n",
    "            CUI1_set.add(row[1])\n",
    "        if row[2] not in CUI2_set:\n",
    "            CUI2_set.add(row[2])\n",
    "        if row[1] not in rela_dict.keys():\n",
    "            rela_dict[row[1]] = [row[2]]\n",
    "        else:\n",
    "            rela_dict[row[1]].append(row[2])\n",
    "            \n",
    "CUI1_list = list(CUI1_set)\n",
    "CUI1_list_len = len(CUI1_list)\n",
    "CUI2_list = list(CUI2_set)     \n",
    "CUI2_list_len = len(CUI2_list)\n",
    "\n",
    "def find_similar(target, corpus, n):\n",
    "    # find top n phrases in corpus that contains the most common words as the target\n",
    "    target_words = set(target.split())\n",
    "\n",
    "    top_n_words = [(-1,' ')]*n\n",
    "    for i in corpus:\n",
    "        if i==target:\n",
    "            continue\n",
    "        sample_words = set(i.split())\n",
    "        common = len(target_words & sample_words)\n",
    "        if common > top_n_words[-1][0]:\n",
    "            top_n_words[-1] = (common, i)\n",
    "            top_n_words.sort(key=lambda x: x[0], reverse = True)\n",
    "    return top_n_words\n",
    "\n",
    "\n",
    "n = 4\n",
    "\n",
    "print('RELA_count= ', RELA_count)\n",
    "data_N = RELA_count//2\n",
    "\n",
    "cui1_list = []\n",
    "cui2_list = []\n",
    "\n",
    "bar = progressbar.ProgressBar(maxval=100, \\\n",
    "    widgets=[progressbar.Bar('=', '[', ']'), ' ', progressbar.Percentage()])\n",
    "bar.start()\n",
    "\n",
    "for i in range(data_N):\n",
    "    perc = int(i/data_N*50)\n",
    "    bar.update(perc)\n",
    "    # find similar to CUI1\n",
    "    index = random.randint(0,len(CUI1_list)-1)\n",
    "    CUI1_string = CUI1_list[index]\n",
    "    top_n_words = find_similar(CUI1_string,CUI2_list[:int(0.7*CUI2_list_len)],n)\n",
    "\n",
    "    false_concepts_pool = []\n",
    "    for i in top_n_words:\n",
    "        if(i[1] not in rela_dict[CUI1_string]):\n",
    "            false_concepts_pool.append(i[1])\n",
    "    if(len(false_concepts_pool)):\n",
    "        cui1_list.append(CUI1_string)\n",
    "        cui2_list.append(random.choice(false_concepts_pool))\n",
    "\n",
    "for i in range(data_N):\n",
    "    perc = int(50+i/data_N*50)\n",
    "    bar.update(perc)\n",
    "    # find similar to CUI2\n",
    "    index = random.randint(0,len(CUI2_list)-1)\n",
    "    CUI2_string = CUI2_list[index]\n",
    "    top_n_words = find_similar(CUI2_string,CUI1_list[:int(0.7*CUI1_list_len)],n)\n",
    "\n",
    "    false_concepts_pool = []\n",
    "    for i in top_n_words:\n",
    "        if(CUI2_string not in rela_dict[i[1]]):\n",
    "            false_concepts_pool.append(i[1])\n",
    "    if(len(false_concepts_pool)):\n",
    "        cui1_list.append(random.choice(false_concepts_pool))\n",
    "        cui2_list.append(CUI2_string)\n",
    "\n",
    "bar.finish()\n",
    "\n",
    "df2 = pd.DataFrame(np.array([cui1_list,cui2_list]).T,\n",
    "                   columns=['CUI1', 'CUI2'])\n",
    "\n",
    "if not os.path.isdir(RELA):\n",
    "    os.mkdir(RELA)\n",
    "\n",
    "\n",
    "df2.to_csv('./'+RELA+'/negative_'+RELA+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate negative pairs by using similar relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lines_count =  35227\n",
      "break!!\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import progressbar\n",
    "import string\n",
    "import os\n",
    "\n",
    "RELA = 'disease_has_finding'\n",
    "neg_RELA = 'mapped_to'\n",
    "\n",
    "if not os.path.isdir(RELA):\n",
    "    os.mkdir(RELA)\n",
    "    \n",
    "lines_count = 0 \n",
    "with open('./relas/'+RELA+'.csv') as f:\n",
    "    lines_count = len(f.readlines(  ))\n",
    "    print('lines_count = ', lines_count)\n",
    "\n",
    "RELA_count = 0\n",
    "with open('./relas/'+neg_RELA+'.csv', newline='') as f:\n",
    "    reader = csv.reader(f, delimiter=',')\n",
    "    row1 = next(reader)\n",
    "    with open('./'+RELA+'/negative_'+RELA+'_with_'+neg_RELA+'.csv', 'w') as write_f:\n",
    "        writer = csv.writer(write_f, delimiter=',',\n",
    "                            quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        writer.writerow(['','CUI1', 'CUI2'])\n",
    "        for row in reader:\n",
    "            writer.writerow(row)\n",
    "            RELA_count += 1\n",
    "            if(RELA_count == lines_count//5):\n",
    "                print('break!!')\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_CUI1_list = []\n",
    "pos_CUI2_list = []\n",
    "pos_label_list = []\n",
    "\n",
    "neg_CUI1_list = []\n",
    "neg_CUI2_list = []\n",
    "neg_label_list = []\n",
    "\n",
    "negative_files = ['negative_'+RELA+'.csv']\n",
    "\n",
    "for file in negative_files:\n",
    "    with open('./'+RELA+'/'+file, newline='') as f:\n",
    "        reader = csv.reader(f, delimiter=',')\n",
    "        row1 = next(reader)\n",
    "        for row in reader:\n",
    "            neg_CUI1_list.append(row[1])\n",
    "            neg_CUI2_list.append(row[2])\n",
    "            neg_label_list.append(0)\n",
    "\n",
    "with open('./relas/'+RELA+'.csv', newline='') as f:\n",
    "    reader = csv.reader(f, delimiter=',')\n",
    "    row1 = next(reader)\n",
    "    all_pos = []\n",
    "    for row in reader:\n",
    "        all_pos.append(row)\n",
    "\n",
    "    for i in range(len(all_pos)):\n",
    "        n = random.randint(0,len(all_pos)-1)\n",
    "        pos_CUI1_list.append(all_pos[n][1])\n",
    "        pos_CUI2_list.append(all_pos[n][2])\n",
    "        pos_label_list.append(1)\n",
    "\n",
    "train_CUI1 = neg_CUI1_list[:int(0.7*len(neg_CUI1_list))]   +pos_CUI1_list[:int(0.7*len(pos_CUI1_list))]\n",
    "train_CUI2 = neg_CUI2_list[:int(0.7*len(neg_CUI2_list))]   +pos_CUI2_list[:int(0.7*len(pos_CUI2_list))]\n",
    "train_label = neg_label_list[:int(0.7*len(neg_label_list))]+pos_label_list[:int(0.7*len(pos_label_list))]\n",
    "\n",
    "dev_CUI1 = neg_CUI1_list[int(0.7*len(neg_CUI1_list)):int(0.9*len(neg_CUI1_list))]    +pos_CUI1_list[int(0.7*len(pos_CUI1_list)):int(0.9*len(pos_CUI1_list))]\n",
    "dev_CUI2 = neg_CUI2_list[int(0.7*len(neg_CUI2_list)):int(0.9*len(neg_CUI2_list))]    +pos_CUI2_list[int(0.7*len(pos_CUI2_list)):int(0.9*len(pos_CUI2_list))]\n",
    "dev_label = neg_label_list[int(0.7*len(neg_label_list)):int(0.9*len(neg_label_list))]+pos_label_list[int(0.7*len(pos_label_list)):int(0.9*len(pos_label_list))]\n",
    "\n",
    "test_CUI1 = neg_CUI1_list[int(0.9*len(neg_CUI1_list)):]   +pos_CUI1_list[int(0.9*len(pos_CUI1_list)):]\n",
    "test_CUI2 = neg_CUI2_list[int(0.9*len(neg_CUI2_list)):]   +pos_CUI2_list[int(0.9*len(pos_CUI2_list)):]\n",
    "test_label = neg_label_list[int(0.9*len(neg_label_list)):]+pos_label_list[int(0.9*len(pos_label_list)):]\n",
    "\n",
    "df1 = pd.DataFrame(np.array([train_CUI1,train_CUI2,train_label]).T,\n",
    "                   columns=['CUI1', 'CUI2', 'label'])\n",
    "\n",
    "\n",
    "df2 = pd.DataFrame(np.array([dev_CUI1,dev_CUI2,dev_label]).T,\n",
    "                   columns=['CUI1', 'CUI2', 'label'])\n",
    "\n",
    "df3 = pd.DataFrame(np.array([test_CUI1,test_CUI2,test_label]).T,\n",
    "                   columns=['CUI1', 'CUI2', 'label'])\n",
    "\n",
    "df1.to_csv(RELA+'/train.csv')\n",
    "df2.to_csv(RELA+'/dev.csv')\n",
    "df3.to_csv(RELA+'/test.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
